#!/usr/bin/env zeshy
# --------------------( LICENSE                            )--------------------
# Copyright 2007-2017 by Cecil Curry.
# See "LICENSE" for additional details.

:parcel <<'/---'
Core *URL* (i.e., Uniform Resource Locator) functionality.
/---

# ....................{ CANONICALIZERS                     }....................
#FIXME: The "wget"-based implementation is currently broken! See below.

# If:
#
# * "curl" is pathable, prefer such command, which (unsurprisingly) provides a
#   considerably simpler method of canonicalizing URLs than "wget".
# * "wget" is pathable, fallback to such command.
:declare_func_if_pathable_or_noop\
    ':void :canonicalize_url(:Str url_str_name) [var_name_suffix="__cu"]'\
    ''\
    curl '
        :Str.set "${url_str_name__cu}" "$(command curl\
            --head\
            --location\
            --show-error\
            --silent\
            --output /dev/null\
            --write-out ''%{url_effective}''\
            "${(P)url_str_name__cu}"
        )"'\
    wget '
        :str page_headers__cu

        # Capture all pager headers sent by the webservers serving such URL and
        # all . Dismantled, this is:
        #
        # * "--max-redirect=...", resolving nearly arbitrarily many redirections
        #   (rather than failing at the 21st redirection).
        # * "--output-document=-", outputting to standard output (to be captured
        #   by such process substitution).
        # * "--spider", retrieving only page headers (rather than page content).
        # * "--tries=1", failing if the first attempt fails (rather than
        #   retrying 20 times).
        # * ":=stdout", redirecting standard error to output. Nonsensically,
        #   "wget" always prints such headers to standard error -- and provides
        #   no means of altering such behavior. *sigh*
        page_headers__cu="$({
            command wget\
                --max-redirect=999999\
                --output-document=-\
                --spider\
                --tries=1\
                "${(P)url_str_name__cu}"
        } :=stdout)"

        #FIXME: Actually implement
        #:set_string_to_string_line_last_matching_pcre_group_if_found().
        #Wonder how we''ll do that, incidentally? Two methods, as we see it:
        #
        #1. Split such string on newlines into a list and search such list from
        #   the *END* for the first matching line.
        #2. Iteratively apply such PCRE to such list from the *BEGINNING*. The
        #   last captured group if any is the desired group.
        #
        #O.K.; clearly, on arbitrarily large strings, the former solution is
        #(probably) the most efficient. Although the storage costs are
        #significantly higher, we don''t expect to ever apply such function to
        #grossly corpulescent strings. In such case, iteratively searching from
        #the beginning of a large string merely to ignore most such matches
        #seems particularly inefficient. Besides, the former solution is
        #modestly clever... modestly.

        # If such URL redirects to another URL, set such string to the last URL
        # such URL transitively redirects to; else, leave such string unaltered.
        {
            :set_string_to_string_line_last_matching_pcre_group_if_found\
                "${url_str_name__cu}"\
                "${page_headers__cu}"\
                ''^Location: ([^ ]++) ''
        } :=failure.ignore' <<'/---'
Canonicalize the value of the passed string variable as a URL. If such URL
points to an HTTP redirection rather than a page, such canonicalization
attempts to iteratively resolve such redirection until the resulting URL either
resolves to a page or exceeds a sensible timeout for doing so. In the latter
case, an exception is thrown: e.g.,

.:canonicalize_url()
==========================================
[source]
------------------------------------------
# If http://dieoff.com redirects to http://holoceneextinction.com
# redirects to http://raiazome.com, then...
>>> :str url='http://dieoff.com'
>>> :canonicalize_url url
>>> :stdout.echo "${url}"
http://raiazome.com
------------------------------------------
==========================================
/---
